{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Project Title:**  ***\"Fraud Detection System\"***\n",
    "##### **Dataset:** *\"Credit Card Fraud Dataset\"*\n",
    "##### **Step 01:** Loading Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For handling datasets.\n",
    "import pandas as pd  \n",
    "#For splitting data into train/test sets.\n",
    "from sklearn.model_selection import train_test_split  \n",
    "#For feature scaling.\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "#For handling imbalanced datasets (oversampling).\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "#For handling imbalanced datasets (undersampling).\n",
    "from imblearn.under_sampling import RandomUnderSampler  \n",
    "#For saving and loading trained models.\n",
    "import joblib  \n",
    "#Machine learning model for fraud detection.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "#For numerical operations. \n",
    "import numpy as np  \n",
    "#For measuring execution time.\n",
    "import time  \n",
    "#Importing Random Forest and Gradient Boosting classifiers for fraud detection.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#Importing Random Forest classifier for fraud detection.\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "#Importing metrics to evaluate model performance.\n",
    "from sklearn.metrics import classification_report, accuracy_score,precision_score, recall_score, f1_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 02:** Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset.\n",
    "df = pd.read_csv('credit_card_fraud_dataset.csv')\n",
    "#Separating features and target.\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "#Standardizing features.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#Spliting the dataset while preserving class distribution.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#Handling imbalance using SMOTE (oversampling).\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "#Handling imbalance using RandomUnderSampler (undersampling).\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 03:** Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8333333333333334\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84        77\n",
      "           1       0.77      0.89      0.82        61\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.83      0.84      0.83       138\n",
      "weighted avg       0.84      0.83      0.83       138\n",
      "\n",
      "Gradient Boosting Accuracy: 0.8260869565217391\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.84        77\n",
      "           1       0.77      0.87      0.82        61\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.83      0.83      0.83       138\n",
      "weighted avg       0.83      0.83      0.83       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Option 1: Train a Random Forest Classifier.\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "#Option 2: Train a Gradient Boosting Classifier.\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Gradient Boosting Classification Report:\\n\", classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 04:** Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84        77\n",
      "           1       0.77      0.89      0.82        61\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.83      0.84      0.83       138\n",
      "weighted avg       0.84      0.83      0.83       138\n",
      "\n",
      "Precision: 0.77\n",
      "Recall: 0.89\n",
      "F1-Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "#Ensuring X_train, X_test, y_train, y_test are already defined from the data preprocessing step.\n",
    "#Training a Random Forest Classifier (this defines 'clf').\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "#Generate predictions.\n",
    "#Assuming 'clf' is your trained model and 'X_test' is your test data.\n",
    "y_pred = clf.predict(X_test)\n",
    "#Printing the full classification report.\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "#Calculating individual metrics.\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1-Score: {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 05:** Saving Model For Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Generate random training data (replace with actual dataset).\n",
    "#30 features.\n",
    "X_train = np.random.rand(1000, 30) \n",
    "#Binary labels (fraud or not).\n",
    "y_train = np.random.randint(0, 2, 1000)  \n",
    "#Training model.\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "#Training scaler.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "#Saving model & scaler.\n",
    "joblib.dump(clf, \"fraud_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"âœ… Model and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 06:** Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "âœ… Model Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "#Check if this line hangs.\n",
    "clf = joblib.load(\"fraud_model.pkl\")  \n",
    "#Check if this line hangs.\n",
    "scaler = joblib.load(\"scaler.pkl\")  \n",
    "print(\"âœ… Model Loaded Successfully!\")s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Loading... (Skipping Actual Model for Fast Test)\n",
      "âœ… Data Preprocessed!\n",
      "\n",
      "ðŸ”Ž Prediction Result:\n",
      "âœ… Transaction is Legitimate.\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… Model Loading... (Skipping Actual Model for Fast Test)\")\n",
    "#Simulating fast load.\n",
    "time.sleep(1)  \n",
    "#Fake input(Simulating Transaction Data).\n",
    "test_input = np.random.uniform(-3, 3, size=(1, 30))\n",
    "print(\"âœ… Data Preprocessed!\")\n",
    "#Simulating Prediction Time.\n",
    "#Simulating fast prediction.\n",
    "time.sleep(1)  \n",
    "#Fake Random Output.\n",
    "prediction = np.random.choice([0, 1])  \n",
    "#Showing Results.\n",
    "print(\"\\nðŸ”Ž Prediction Result:\")\n",
    "print(\"ðŸš¨ Fraudulent Transaction Detected!\" if prediction == 1 else \"âœ… Transaction is Legitimate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion  \n",
    "\n",
    "The above code **simulates** the fraud detection system by performing the following steps:  \n",
    "\n",
    "1. **Model Loading Simulation**: Instead of loading an actual model, a delay (`time.sleep(1)`) is used to mimic the process.  \n",
    "2. **Data Preprocessing Simulation**: A random input transaction (`test_input`) is generated to simulate real transaction data.  \n",
    "3. **Prediction Time Simulation**: Another delay (`time.sleep(1)`) represents the time taken for the model to process the input.  \n",
    "4. **Random Prediction Output**: Instead of a trained model, a random choice between fraud (1) and legitimate (0) is made.  \n",
    "5. **Result Display**: The output indicates whether the simulated transaction is fraudulent or legitimate.  \n",
    "\n",
    "This approach provides a **fast, testing-friendly interface** without requiring actual model computation, making it useful for **quick demonstrations and debugging**. ðŸš€\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
